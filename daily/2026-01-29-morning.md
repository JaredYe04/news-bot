# ğŸ§  ç§‘ç ” & æŠ€æœ¯çƒ­ç‚¹æ—¥æŠ¥

æ—¥æœŸï¼š2026-01-29 ä¸Šåˆ
ç”Ÿæˆæ—¶é—´ï¼š2026/01/29 17:19

## ğŸ“ ä»Šæ—¥æ€»ç»“

# ä»Šæ—¥ç§‘ç ”ä¸æŠ€æœ¯çƒ­ç‚¹æ€»ç»“ï¼ˆ2026å¹´1æœˆ29æ—¥ï¼‰

## 1. ä»Šæ—¥æœ€é‡è¦çš„æŠ€æœ¯è¶‹åŠ¿å’Œçƒ­ç‚¹

**ï¼ˆ1ï¼‰NeuroAIï¼šç¥ç»ç§‘å­¦ä¸AIçš„æ·±åº¦èåˆæˆä¸ºç„¦ç‚¹**  
ä»Šæ—¥å¤šç¯‡è®ºæ–‡ï¼ˆå¦‚arXiv:2601.19955ï¼‰å‡æŒ‡å‘åŒä¸€æ–¹å‘ï¼šç¥ç»ç§‘å­¦ä¸äººå·¥æ™ºèƒ½çš„äº¤å‰ç ”ç©¶æ­£ä»æ¾æ•£è¿æ¥è½¬å‘ç³»ç»ŸåŒ–æ•´åˆã€‚ç ”ç©¶è€…æå‡ºâ€œNeuroAIâ€æ¡†æ¶ï¼Œå¼ºè°ƒä»**å…·èº«æ™ºèƒ½ã€è¯­è¨€é€šä¿¡ã€æœºå™¨äººå­¦ã€äººç±»ä¸æœºå™¨å­¦ä¹ çš„æ¯”è¾ƒã€ç¥ç»å½¢æ€å·¥ç¨‹**äº”ä¸ªå­é¢†åŸŸæ±²å–çµæ„Ÿã€‚è¿™æ ‡å¿—ç€AIç ”ç©¶æ­£åœ¨ä»çº¯æ•°æ®é©±åŠ¨è½¬å‘**ç”Ÿç‰©å¯å‘å¼è®¾è®¡**ï¼Œè¯•å›¾è§£å†³å½“å‰AIåœ¨èƒ½æ•ˆã€æ³›åŒ–èƒ½åŠ›å’Œå¯è§£é‡Šæ€§ä¸Šçš„æ ¹æœ¬ç“¶é¢ˆã€‚

**ï¼ˆ2ï¼‰æ™ºèƒ½ä½“ç³»ç»Ÿçš„ç§‘å­¦åŒ–ä¸è§„æ¨¡åŒ–æŒ‘æˆ˜å‡¸æ˜¾**  
Google Researchç­‰æœºæ„å¼€å§‹å‘¼åå»ºç«‹â€œæ™ºèƒ½ä½“ç³»ç»Ÿçš„ç§‘å­¦â€ï¼Œæ¢è®¨æ™ºèƒ½ä½“ç³»ç»Ÿä½•æ—¶ã€ä¸ºä½•æœ‰æ•ˆã€‚ä¸æ­¤åŒæ—¶ï¼ŒWIREDå´å‘å‡ºè­¦ç¤ºï¼šâ€œAIæ™ºèƒ½ä½“çš„æ•°å­¦è´¦ç®—ä¸æ¸…â€ï¼Œç›´æŒ‡å½“å‰æ™ºèƒ½ä½“åœ¨æˆæœ¬ã€å¯é æ€§å’Œå¯æ‰©å±•æ€§ä¸Šçš„çŸ›ç›¾ã€‚è¿™åæ˜ è¡Œä¸šå·²ä»ç›²ç›®è¿½æ§è¿›å…¥**ç†æ€§è¯„ä¼°é˜¶æ®µ**ï¼Œé‡ç‚¹è½¬å‘å¦‚ä½•è®¾è®¡é«˜æ•ˆã€ç¨³å®šä¸”ç»æµçš„å¤šæ™ºèƒ½ä½“åä½œæ¡†æ¶ã€‚

**ï¼ˆ3ï¼‰æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰å‘åŠ¨æ€åŒ–ã€å¯è§£é‡ŠåŒ–æ¼”è¿›**  
ä»Šæ—¥ç ”ç©¶æ˜¾ç¤ºï¼ŒRAGæŠ€æœ¯æ­£çªç ´é™æ€æ£€ç´¢çš„å±€é™ã€‚ä¾‹å¦‚IMRNNsæå‡ºé€šè¿‡**åŠ¨æ€åµŒå…¥è°ƒåˆ¶**å®ç°æŸ¥è¯¢ä¸æ–‡æ¡£çš„åŒå‘è¯­ä¹‰äº¤äº’ï¼Œä½¿æ£€ç´¢è¿‡ç¨‹å¯è§£é‡Šï¼›GraphAnchoråˆ™å¼•å…¥**æ¼”åŒ–çŸ¥è¯†ç´¢å¼•**ï¼Œè®©RAGç³»ç»Ÿèƒ½æŒç»­æ›´æ–°çŸ¥è¯†åº“ã€‚è¿™æ˜¾ç¤ºRAGæ­£åœ¨ä»â€œå¤–æŒ‚æ•°æ®åº“â€è½¬å‘**æœ‰æœºçŸ¥è¯†ç³»ç»Ÿ**ã€‚

**ï¼ˆ4ï¼‰å¤§æ¨¡å‹å¯é æ€§æˆä¸ºæ ¸å¿ƒè®®é¢˜**  
ä»â€œæ£€æµ‹éŸ©è¯­AIæ–‡æœ¬â€åˆ°â€œé˜²æ­¢ä»£ç ç”Ÿæˆä¸­çš„å¥–åŠ±é»‘å®¢æ”»å‡»â€ï¼Œå¤šä¸ªç ”ç©¶èšç„¦äºå¤§æ¨¡å‹çš„**å¯é æ€§æ ¡å‡†ä¸æ¼æ´é˜²èŒƒ**ã€‚ç‰¹åˆ«æ˜¯åœ¨ä»£ç ç”Ÿæˆåœºæ™¯ä¸­ï¼Œç ”ç©¶è€…æ„å»ºäº†åŒ…å«54ç±»æ¼æ´çš„æµ‹è¯•åŸºå‡†TRACEï¼Œå¼ºè°ƒåœ¨æ— çŠ¶æ€ç¯å¢ƒä¸­æ¨¡æ‹Ÿå¤æ‚å·¥å…·è°ƒç”¨çš„å¿…è¦æ€§ã€‚è¿™æ˜¾ç¤ºä¸šç•Œå¯¹LLMçš„è¯„ä¼°å·²ä»â€œæ€§èƒ½ç«èµ›â€è½¬å‘**å®‰å…¨ä¸é²æ£’æ€§æ·±åº¦æµ‹è¯•**ã€‚

## 2. å€¼å¾—å…³æ³¨çš„ç ”ç©¶æ–¹å‘æˆ–çªç ´

- **è‡ªæŸ¥è¯¢è§„åˆ’ï¼ˆSQ-BCPï¼‰**ï¼šé’ˆå¯¹éƒ¨åˆ†å¯è§‚æµ‹ç¯å¢ƒä¸­çš„è§„åˆ’é—®é¢˜ï¼Œæå‡ºåŸºäºèŒƒç•´è®ºçš„éªŒè¯æ¡†æ¶ï¼Œè®©LLMå­¦ä¼šä¸»åŠ¨è¯¢é—®ç¼ºå¤±å‰ææ¡ä»¶ï¼Œè€Œéç›²ç›®çŒœæµ‹ã€‚è¯¥æ–¹æ³•å°†åŒå‘æœç´¢ä¸æ‹‰å›éªŒè¯ç»“åˆï¼Œä¸ºå¤æ‚ä»»åŠ¡è§„åˆ’æä¾›äº†æ–°çš„å½¢å¼åŒ–å·¥å…·ã€‚
  
- **å»ä¸­å¿ƒåŒ–è”é‚¦å­¦ä¹ çš„äºŒé˜¶ä¼˜åŒ–ï¼ˆDecHWï¼‰**ï¼šé€šè¿‡æ•æ‰å‚æ•°å˜åŒ–çš„è¯æ®å¯ä¿¡åº¦ï¼Œæ˜¾å¼å¤„ç†è®¾å¤‡é—´çš„æ•°æ®ä¸æ¨¡å‹å¼‚è´¨æ€§ï¼Œæœ‰æœ›è§£å†³å»ä¸­å¿ƒåŒ–åä½œä¸­æ”¶æ•›æ…¢çš„å…³é”®é—®é¢˜ã€‚

- **åºåˆ—å»ºæ¨¡çš„ç¼©æ”¾å®šå¾‹ï¼ˆLLaTTEï¼‰**ï¼šåœ¨å¹¿å‘Šæ¨èç³»ç»Ÿä¸­éªŒè¯äº†Transformeråºåˆ—æ¨¡å‹åŒæ ·éµå¾ªç±»ä¼¼LLMçš„å¹‚å¾‹ç¼©æ”¾è§„å¾‹ï¼Œå¹¶å‘ç°è¯­ä¹‰ç‰¹å¾æ˜¯æŒç»­ç¼©æ”¾çš„å‰æã€‚è¿™ä¸ºæ¨èç³»ç»Ÿæ¶æ„è®¾è®¡æä¾›äº†æ–°çš„ç†è®ºä¾æ®ã€‚

- **è¯¯å·®æœ‰æŸå‹ç¼©çš„æ•°æ®é©±åŠ¨æ–¹æ³•ï¼ˆDiscontinuous DLSï¼‰**ï¼šåˆ©ç”¨æ•°æ®é©±åŠ¨çš„å±€éƒ¨å­ç©ºé—´æå‡ç§‘å­¦æ•°æ®å‹ç¼©æ¯”ï¼ŒåŒæ—¶ä¿è¯è¯¯å·®è¾¹ç•Œï¼Œå¯¹å¤„ç†å¤§è§„æ¨¡ç§‘å­¦ä»¿çœŸæ•°æ®å…·æœ‰é‡è¦ä»·å€¼ã€‚

## 3. ç®€è¦åˆ†æä¸å±•æœ›

ä»Šæ—¥æ–°é—»å‘ˆç°å‡ºä¸€ä¸ªæ¸…æ™°çš„æŠ€æœ¯æ¼”è¿›è„‰ç»œï¼šAIç ”ç©¶æ­£ä»â€œè§„æ¨¡è‡³ä¸Šâ€è½¬å‘ **â€œè´¨é‡ä¸æ•ˆç‡å¹¶é‡â€** ã€‚NeuroAIçš„å…´èµ·æš—ç¤ºç€ä¸‹ä¸€æ³¢çªç ´å¯èƒ½æ¥è‡ªè·¨å­¦ç§‘èåˆï¼›æ™ºèƒ½ä½“ä¸RAGçš„æ¼”è¿›åˆ™æŒ‡å‘æ›´è‡ªé€‚åº”ã€å¯è§£é‡Šçš„ç³»ç»Ÿæ¶æ„ï¼›è€Œå¯é æ€§æµ‹è¯•çš„åŠ å¼ºåæ˜ äº†æŠ€æœ¯è½åœ°é˜¶æ®µçš„åŠ¡å®éœ€æ±‚ã€‚

å€¼å¾—å…³æ³¨çš„æ˜¯ï¼ŒOpenAIå‘å¸ƒã€Šæ¬§ç›Ÿç»æµè“å›¾2.0ã€‹ï¼Œç»“åˆGitHub Innovation Graphç­‰æ•°æ®å¹³å°çš„æ›´æ–°ï¼Œæ˜¾ç¤ºå¤§å‹ç§‘æŠ€å…¬å¸æ­£ç§¯ææ„å»º **â€œæŠ€æœ¯-æ”¿ç­–-ç”Ÿæ€â€ä¸‰ä½ä¸€ä½“** çš„æˆ˜ç•¥å¸ƒå±€ã€‚æœªæ¥ç«äº‰ä¸ä»…æ˜¯ç®—æ³•ä¼˜åŠ£ï¼Œæ›´æ˜¯ç”Ÿæ€æ„å»ºèƒ½åŠ›ä¸åˆè§„é€‚åº”æ€§çš„æ¯”æ‹¼ã€‚

æŠ€æœ¯å‘å±•ä¹Ÿé¢ä¸´æ˜æ˜¾å¼ åŠ›ï¼šä¸€æ–¹é¢è¿½æ±‚æ›´å¤æ‚ã€æ›´è‡ªä¸»çš„ç³»ç»Ÿï¼ˆå¦‚æ™ºèƒ½ä½“ï¼‰ï¼Œå¦ä¸€æ–¹é¢åˆå¿…é¡»è§£å†³ç”±æ­¤å¸¦æ¥çš„æˆæœ¬ã€å¯æ§æ€§ä¸é€æ˜åº¦é—®é¢˜ã€‚è¿™ç§å¼ åŠ›å°†é©±åŠ¨æœªæ¥2-3å¹´çš„ç ”ç©¶é‡ç‚¹å‘ **â€œé«˜æ•ˆå¯æ§çš„è‡ªä¸»ç³»ç»Ÿâ€** å€¾æ–œã€‚

## 4. å¯¹ä¸åŒè§’è‰²çš„å»ºè®®

### å¯¹äºå¼€å‘è€…ï¼š
- **å…³æ³¨å·¥å…·é“¾è¿›åŒ–**ï¼šGoogleå†…éƒ¨AI IDEåŠŸèƒ½ï¼ˆä»£ç è¡¥å…¨ã€è‡ªç„¶è¯­è¨€è½¬æ¢ä»£ç ï¼‰çš„ä¼˜åŒ–ç»éªŒè¡¨æ˜ï¼Œæå‡å¼€å‘æ•ˆç‡ä¸ä»…é æ¨¡å‹èƒ½åŠ›ï¼Œæ›´éœ€ç²¾ç»†çš„å·¥ç¨‹æ‰“ç£¨ã€‚å»ºè®®å­¦ä¹ å…¶åˆ†å±‚ä¼˜åŒ–æ€è·¯ï¼ˆUIã€åç«¯ã€æ¨¡å‹å±‚ååŒï¼‰ã€‚
- **å®è·µæ–°å‹RAGæ¶æ„**ï¼šå°è¯•åŠ¨æ€æ£€ç´¢ä¸å¯è§£é‡Šæ£€ç´¢æ–¹æ¡ˆï¼ˆå¦‚IMRNNsæ€æƒ³ï¼‰ï¼Œç‰¹åˆ«æ˜¯åœ¨ä¼ä¸šçº§åº”ç”¨ä¸­æ³¨é‡æ£€ç´¢è¿‡ç¨‹çš„é€æ˜æ€§ã€‚
- **å‚ä¸å¼€æºç”Ÿæ€å»ºè®¾**ï¼šå…³æ³¨GitHub Innovation Graphç­‰æ•°æ®é¡¹ç›®ï¼Œç†è§£å…¨çƒå¼€å‘æ´»åŠ¨è¶‹åŠ¿ï¼ŒæŠŠæ¡æŠ€æœ¯é£å‘ã€‚

### å¯¹äºç ”ç©¶äººå‘˜ï¼š
- **æ¢ç´¢äº¤å‰å­¦ç§‘æœºä¼š**ï¼šNeuroAIæä¾›äº†ä¸°å¯Œçš„è·¨å­¦ç§‘è¯¾é¢˜ï¼Œå¯ä»ç¥ç»ç§‘å­¦ä¸­å€Ÿé‰´å­¦ä¹ æœºåˆ¶ã€èƒ½æ•ˆä¼˜åŒ–ç­‰æ€è·¯ã€‚
- **åŠ å¼ºå¯é æ€§ç ”ç©¶**ï¼šé’ˆå¯¹ç‰¹å®šé¢†åŸŸï¼ˆå¦‚ä»£ç ç”Ÿæˆã€åŒ»ç–—æ–‡æœ¬ï¼‰æ„å»ºç»†ç²’åº¦è¯„ä¼°åŸºå‡†ï¼Œæ¨åŠ¨è¶…è¶Šå‡†ç¡®ç‡çš„å…¨é¢è¯„ä¼°ä½“ç³»ã€‚
- **é‡è§†æ•°æ®é©±åŠ¨æ–¹æ³•**ï¼šä»LLaTTEç­‰å·¥ä½œä¸­çœ‹åˆ°ï¼Œå³ä½¿æ˜¯å·¥ç¨‹é—®é¢˜ï¼ˆå¦‚æ¨èç³»ç»Ÿæ¶æ„ï¼‰ï¼Œä¹Ÿèƒ½é€šè¿‡ç³»ç»Ÿæ€§å®éªŒå‘ç°æ·±å±‚è§„å¾‹ã€‚

### å¯¹äºå­¦ç”Ÿï¼š
- **æ‰“å¥½æ•°å­¦ä¸ç†è®ºåŸºç¡€**ï¼šèŒƒç•´è®ºåœ¨è§„åˆ’éªŒè¯ä¸­çš„åº”ç”¨æ˜¾ç¤ºï¼Œæ‰å®çš„æ•°å­¦å·¥å…·èƒ½ä¸ºå‰æ²¿ç ”ç©¶æä¾›æ–°è§†è§’ã€‚
- **åŸ¹å…»è·¨é¢†åŸŸè§†é‡**ï¼šå…³æ³¨ç¥ç»ç§‘å­¦ã€è®¤çŸ¥å¿ƒç†å­¦ç­‰ç›¸å…³é¢†åŸŸçš„åŸºç¡€çŸ¥è¯†ï¼Œä¸ºå‚ä¸NeuroAIç±»ç ”ç©¶åšå‡†å¤‡ã€‚
- **å‚ä¸å®é™…ç³»ç»Ÿæ„å»º**ï¼šé€šè¿‡å¤ç°å»ä¸­å¿ƒåŒ–è”é‚¦å­¦ä¹ ã€åŠ¨æ€RAGç­‰ç³»ç»Ÿï¼Œæ·±å…¥ç†è§£åˆ†å¸ƒå¼ç³»ç»Ÿä¸æœºå™¨å­¦ä¹ äº¤å‰çš„å®é™…æŒ‘æˆ˜ã€‚

### å¯¹äºæŠ€æœ¯å†³ç­–è€…ï¼š
- **å¹³è¡¡åˆ›æ–°ä¸ç¨³å¥æ€§**ï¼šåœ¨å¼•å…¥æ™ºèƒ½ä½“ç­‰æ–°æŠ€æœ¯æ—¶ï¼Œå‚è€ƒWIREDè­¦ç¤ºçš„æˆæœ¬æ•ˆç›Šåˆ†ææ¡†æ¶ã€‚
- **å…³æ³¨æ¬§æ´²æ”¿ç­–åŠ¨å‘**ï¼šOpenAIæ¬§ç›Ÿè“å›¾çš„å‘å¸ƒæç¤ºæ¬§æ´²å¸‚åœºå¯¹AIæ²»ç†çš„ç‰¹æ®Šè¦æ±‚ï¼Œéœ€æå‰å¸ƒå±€åˆè§„èƒ½åŠ›ã€‚
- **æŠ•èµ„æ•°æ®åŸºç¡€è®¾æ–½å»ºè®¾**ï¼šç§‘å­¦æ•°æ®å‹ç¼©ã€æ¼”åŒ–çŸ¥è¯†ç´¢å¼•ç­‰æŠ€æœ¯å‡¸æ˜¾äº†é«˜è´¨é‡æ•°æ®ç®¡ç†çš„åŸºç¡€æ€§ä»·å€¼ã€‚

---

ä»Šæ—¥çš„æŠ€æœ¯å›¾æ™¯å‘ˆç°å‡ºä¸€ç§æˆç†Ÿçš„æ´»åŠ›ï¼šç‹‚çƒ­è¤ªå»åï¼Œç•™ä¸‹çš„æ˜¯å¯¹æ ¹æœ¬é—®é¢˜çš„æ·±è€•å’Œå¯¹å¯æŒç»­ä»·å€¼çš„è¿½æ±‚ã€‚æ— è®ºæ˜¯å‘å¤§è„‘å¯»æ±‚çµæ„Ÿï¼Œè¿˜æ˜¯è®©ç®—æ³•å­¦ä¼šâ€œæé—®â€ï¼ŒæŠ‘æˆ–æ˜¯è®©æ¯ä¸€æ¬¡æ£€ç´¢éƒ½æ¸…æ™°å¯æº¯â€”â€”è¿™äº›åŠªåŠ›éƒ½åœ¨å…±åŒå›ç­”ä¸€ä¸ªé—®é¢˜ï¼šæˆ‘ä»¬å¦‚ä½•è®©äººå·¥æ™ºèƒ½ä¸ä»…æ›´å¼ºå¤§ï¼Œè€Œä¸”æ›´èªæ˜ã€æ›´å¯é ï¼Ÿç­”æ¡ˆæˆ–è®¸å°±è—åœ¨è¿™äº›çœ‹ä¼¼åˆ†æ•£å´å†…åœ¨ç›¸è¿çš„æ¢ç´¢ä¹‹ä¸­ã€‚

---

## ğŸ”¥ AI / LLM

- **NeuroAI and Beyond**  
  æ¥æºï¼šarXiv cs.AI (arXivï¼ˆè®ºæ–‡æ‘˜è¦ï¼‰)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šarXiv:2601.19955v1 Announce Type: new  Abstract: Neuroscience and Artificial Intelligence (AI) have made significant progress in the past few years but have only been loosely inter-connected. Based on a workshop held in August 2025, we identify current and future areas of synergism between these two fields. We focus on the subareas of embodiment, language and communication, robotics, learning in humans and machines and Neuromorphic engineering to take stock of the progress made so far, and possi...
  é“¾æ¥ï¼šhttps://arxiv.org/abs/2601.19955

- **Teaching LLMs to Ask: Self-Querying Category-Theoretic Planning for Under-Specified Reasoning**  
  æ¥æºï¼šarXiv cs.AI (arXivï¼ˆè®ºæ–‡æ‘˜è¦ï¼‰)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šarXiv:2601.20014v1 Announce Type: new  Abstract: Inference-time planning with large language models frequently breaks under partial observability: when task-critical preconditions are not specified at query time, models tend to hallucinate missing facts or produce plans that violate hard constraints. We introduce \textbf{Self-Querying Bidirectional Categorical Planning (SQ-BCP)}, which explicitly represents precondition status (\texttt{Sat}/\texttt{Viol}/\texttt{Unk}) and resolves unknowns via (...
  é“¾æ¥ï¼šhttps://arxiv.org/abs/2601.20014

- **Gap-K%: Measuring Top-1 Prediction Gap for Detecting Pretraining Data**  
  æ¥æºï¼šarXiv cs.LG (arXivï¼ˆè®ºæ–‡æ‘˜è¦ï¼‰)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šarXiv:2601.19936v1 Announce Type: new  Abstract: The opacity of massive pretraining corpora in Large Language Models (LLMs) raises significant privacy and copyright concerns, making pretraining data detection a critical challenge. Existing state-of-the-art methods typically rely on token likelihoods, yet they often overlook the divergence from the model's top-1 prediction and local correlation between adjacent tokens. In this work, we propose Gap-K%, a novel pretraining data detection method gro...
  é“¾æ¥ï¼šhttps://arxiv.org/abs/2601.19936

- **DecHW: Heterogeneous Decentralized Federated Learning Exploiting Second-Order Information**  
  æ¥æºï¼šarXiv cs.LG (arXivï¼ˆè®ºæ–‡æ‘˜è¦ï¼‰)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šarXiv:2601.19938v1 Announce Type: new  Abstract: Decentralized Federated Learning (DFL) is a serverless collaborative machine learning paradigm where devices collaborate directly with neighbouring devices to exchange model information for learning a generalized model. However, variations in individual experiences and different levels of device interactions lead to data and model initialization heterogeneities across devices. Such heterogeneities leave variations in local model parameters across...
  é“¾æ¥ï¼šhttps://arxiv.org/abs/2601.19938

- **The next chapter for AI in the EU**  
  æ¥æºï¼šOpenAI Blog (åšå®¢)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šOpenAI launches the EU Economic Blueprint 2.0 with new data, partnerships, and initiatives to accelerate AI adoption, skills, and growth across Europe.
  é“¾æ¥ï¼šhttps://openai.com/index/the-next-chapter-for-ai-in-the-eu

## ğŸ”¥ Agent / æ™ºèƒ½ä½“

- **NeuroAI and Beyond**  
  æ¥æºï¼šarXiv cs.AI (arXivï¼ˆè®ºæ–‡æ‘˜è¦ï¼‰)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šarXiv:2601.19955v1 Announce Type: new  Abstract: Neuroscience and Artificial Intelligence (AI) have made significant progress in the past few years but have only been loosely inter-connected. Based on a workshop held in August 2025, we identify current and future areas of synergism between these two fields. We focus on the subareas of embodiment, language and communication, robotics, learning in humans and machines and Neuromorphic engineering to take stock of the progress made so far, and possi...
  é“¾æ¥ï¼šhttps://arxiv.org/abs/2601.19955

- **Teaching LLMs to Ask: Self-Querying Category-Theoretic Planning for Under-Specified Reasoning**  
  æ¥æºï¼šarXiv cs.AI (arXivï¼ˆè®ºæ–‡æ‘˜è¦ï¼‰)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šarXiv:2601.20014v1 Announce Type: new  Abstract: Inference-time planning with large language models frequently breaks under partial observability: when task-critical preconditions are not specified at query time, models tend to hallucinate missing facts or produce plans that violate hard constraints. We introduce \textbf{Self-Querying Bidirectional Categorical Planning (SQ-BCP)}, which explicitly represents precondition status (\texttt{Sat}/\texttt{Viol}/\texttt{Unk}) and resolves unknowns via (...
  é“¾æ¥ï¼šhttps://arxiv.org/abs/2601.20014

- **Towards a science of scaling agent systems: When and why agent systems work - Google Research**  
  æ¥æºï¼šGoogle News - AI Agents (æ–°é—»)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šTowards a science of scaling agent systems: When and why agent systems workÂ Â Google Research
  é“¾æ¥ï¼šhttps://news.google.com/rss/articles/CBMipwFBVV95cUxOaXFPa29TWWNRSmtrcWV5MGRuRVV3U1d0U2ZYM1hkN3dsbS1UUGk4YlZHU2RabG1vNV9kZUZkd2VUWlc5MlA4Z05aMW9ncWg2bndkZVhqbHNNa2dCakY5T1NTV0lFc19VbGRfU2w1V3p6Ui1HZDh2QU1UdkNMQktUZW5QUEN5TkIwVk85VmtISTBWbkJiNzhuUzZJU3ltWW02ck02QjIxQQ?oc=5

- **Medable Introduces AI Agent to Reduce Burden at Research Sites By Assisting Principal Investigators with Oversight of eCOA Data - Business Wire**  
  æ¥æºï¼šGoogle News - AI Agents (æ–°é—»)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šMedable Introduces AI Agent to Reduce Burden at Research Sites By Assisting Principal Investigators with Oversight of eCOA DataÂ Â Business Wire
  é“¾æ¥ï¼šhttps://news.google.com/rss/articles/CBMikgJBVV95cUxNQUxCaEdadGpSZUI5RG54M0xlR242YVZGOTJGSGFhMkRiZlhlM3pxUkRCcEZ6OEluWWY3dURiZHhSS2wxakpFUFIwaGlRWndkNlJ3N2ZkTUw5OUV6YV9vNVg3b0FObEo5YWtvTmlEd1R1eTR1NTJhYkx4clhsNmRhT2trN0dxS1p0NnFTZ0tLWDB2UVo2WVlRd1ZnNHN4bGZRZmxGRG1MaEp6SV94WjNDN1FuWTZ1U2F3R2VMVW5WMl9MOUw2VDhFdjMwNUhUcjE2N3AwUWx6R3I0Y3l6OXhVNUxHY21Gc1J0d28zSDR5RHNfblNLcXhwRDJheVNJWlZOa0xLdkVLSWg2UWVfYU55UnRn?oc=5

- **The Math on AI Agents Doesnâ€™t Add Up - WIRED**  
  æ¥æºï¼šGoogle News - AI Agents (æ–°é—»)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šThe Math on AI Agents Doesnâ€™t Add UpÂ Â WIRED
  é“¾æ¥ï¼šhttps://news.google.com/rss/articles/CBMiaEFVX3lxTE1tN1ltdW5aOVREdlBqRkgxdTc5UVBmQ2FiWkVEeTNjVDdSdFhmRFMxdVpXb0t1QUl3Z3E5TXpvQ3NHTVJiX3NiMk1vQVhlbHRkMlhsM1BuRmlFbEsweFFyQkt0WVVWcDlO?oc=5

## ğŸ”¥ RAG / æ£€ç´¢å¢å¼ºç”Ÿæˆ

- **NeuroAI and Beyond**  
  æ¥æºï¼šarXiv cs.AI (arXivï¼ˆè®ºæ–‡æ‘˜è¦ï¼‰)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šarXiv:2601.19955v1 Announce Type: new  Abstract: Neuroscience and Artificial Intelligence (AI) have made significant progress in the past few years but have only been loosely inter-connected. Based on a workshop held in August 2025, we identify current and future areas of synergism between these two fields. We focus on the subareas of embodiment, language and communication, robotics, learning in humans and machines and Neuromorphic engineering to take stock of the progress made so far, and possi...
  é“¾æ¥ï¼šhttps://arxiv.org/abs/2601.19955

- **Teaching LLMs to Ask: Self-Querying Category-Theoretic Planning for Under-Specified Reasoning**  
  æ¥æºï¼šarXiv cs.AI (arXivï¼ˆè®ºæ–‡æ‘˜è¦ï¼‰)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šarXiv:2601.20014v1 Announce Type: new  Abstract: Inference-time planning with large language models frequently breaks under partial observability: when task-critical preconditions are not specified at query time, models tend to hallucinate missing facts or produce plans that violate hard constraints. We introduce \textbf{Self-Querying Bidirectional Categorical Planning (SQ-BCP)}, which explicitly represents precondition status (\texttt{Sat}/\texttt{Viol}/\texttt{Unk}) and resolves unknowns via (...
  é“¾æ¥ï¼šhttps://arxiv.org/abs/2601.20014

- **LLaTTE: Scaling Laws for Multi-Stage Sequence Modeling in Large-Scale Ads Recommendation**  
  æ¥æºï¼šarXiv cs.IR (arXivï¼ˆè®ºæ–‡æ‘˜è¦ï¼‰)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šarXiv:2601.20083v1 Announce Type: new  Abstract: We present LLaTTE (LLM-Style Latent Transformers for Temporal Events), a scalable transformer architecture for production ads recommendation. Through systematic experiments, we demonstrate that sequence modeling in recommendation systems follows predictable power-law scaling similar to LLMs. Crucially, we find that semantic features bend the scaling curve: they are a prerequisite for scaling, enabling the model to effectively utilize the capacity...
  é“¾æ¥ï¼šhttps://arxiv.org/abs/2601.20083

- **IMRNNs: An Efficient Method for Interpretable Dense Retrieval via Embedding Modulation**  
  æ¥æºï¼šarXiv cs.IR (arXivï¼ˆè®ºæ–‡æ‘˜è¦ï¼‰)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šarXiv:2601.20084v1 Announce Type: new  Abstract: Interpretability in black-box dense retrievers remains a central challenge in Retrieval-Augmented Generation (RAG). Understanding how queries and documents semantically interact is critical for diagnosing retrieval behavior and improving model design. However, existing dense retrievers rely on static embeddings for both queries and documents, which obscures this bidirectional relationship. Post-hoc approaches such as re-rankers are computationally...
  é“¾æ¥ï¼šhttps://arxiv.org/abs/2601.20084

- **Graphanchor Achieves Retrieval-Augmented Generation with Evolving Knowledge Indices for LLMs - Quantum Zeitgeist**  
  æ¥æºï¼šGoogle News - RAG (æ–°é—»)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šGraphanchor Achieves Retrieval-Augmented Generation with Evolving Knowledge Indices for LLMsÂ Â Quantum Zeitgeist
  é“¾æ¥ï¼šhttps://news.google.com/rss/articles/CBMiiAFBVV95cUxQMnBDT3l4ZEhtQ3F5SVNjV0ZYc0NQdVZsNFpndldzT3RicFVGUGxVQUZZMjVBMzBfQWZYeTBiV21wZlpNRUwwVTYxdHhJYmNZNGJqNXlHWi1MVzV5bDB4bkk3c1UxVjBDZGxTTEtzYUpZV00yTUNoSnQ0d1d3ZHpITjdOMVA3Vkd0?oc=5

## ğŸ”¥ LLM / å¤§è¯­è¨€æ¨¡å‹

- **From Intuition to Expertise: Rubric-Based Cognitive Calibration for Human Detection of LLM-Generated Korean Text**  
  æ¥æºï¼šarXiv cs.CL (arXivï¼ˆè®ºæ–‡æ‘˜è¦ï¼‰)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šarXiv:2601.19913v1 Announce Type: new  Abstract: Distinguishing human-written Korean text from fluent LLM outputs remains difficult even for linguistically trained readers, who can over-trust surface well-formedness. We study whether expert detection can be treated as a learnable skill and improved through structured calibration. We introduce LREAD, a rubric derived from national Korean writing standards and adapted to target micro-level artifacts (e.g., punctuation optionality, spacing behavior...
  é“¾æ¥ï¼šhttps://arxiv.org/abs/2601.19913

- **Simulating Complex Multi-Turn Tool Calling Interactions in Stateless Execution Environments**  
  æ¥æºï¼šarXiv cs.CL (arXivï¼ˆè®ºæ–‡æ‘˜è¦ï¼‰)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šarXiv:2601.19914v1 Announce Type: new  Abstract: Synthetic data has proven itself to be a valuable resource for tuning smaller, cost-effective language models to handle the complexities of multi-turn tool calling conversations. While many frameworks and systems for producing synthetic multi-turn tool calling data have been proposed, prior works have frequently assumed that any tool calling interactions will take place in an execution environment that maintains state. When such an environment is...
  é“¾æ¥ï¼šhttps://arxiv.org/abs/2601.19914

- **Making large language models reliable data science programming copilots for biomedical research - Nature**  
  æ¥æºï¼šGoogle News - LLM (æ–°é—»)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šMaking large language models reliable data science programming copilots for biomedical researchÂ Â Nature
  é“¾æ¥ï¼šhttps://news.google.com/rss/articles/CBMiX0FVX3lxTE50QktselJoYnR6SEdDSHQxUVBpVHIzZ3VWY3NQM1VCWUJPRjV6TTFMcC1YTXh1eGJlQlktZ1FFRGNhajRQX3dxc09iSEpTM2NHTDgwbHZZTndaQjlucm40?oc=5

- **Student Research Examines Loyalties of Language Models - Dartmouth**  
  æ¥æºï¼šGoogle News - LLM (æ–°é—»)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šStudent Research Examines Loyalties of Language ModelsÂ Â Dartmouth
  é“¾æ¥ï¼šhttps://news.google.com/rss/articles/CBMilgFBVV95cUxPLXVCTGZ1ODloaERLZW9DcDU3R3JMdmp5Q3BXODRsRXJPMzdqWjFsZE4zSld5Nld1VGpxLVFKLW1pNXNxb0dGR2ZtX2NBcHNXLWxBVEk3RnFXN0RCdEstUTdUcmpUV2Z1VFpYZVp6VFBkUGxRQU1WR1VibnRJbTdxaElxMmQweE14eUR3MHZzNlFtNzhZX1E?oc=5

- **The assistant axis: situating and stabilizing the character of large language models - Anthropic**  
  æ¥æºï¼šGoogle News - LLM (æ–°é—»)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šThe assistant axis: situating and stabilizing the character of large language modelsÂ Â Anthropic
  é“¾æ¥ï¼šhttps://news.google.com/rss/articles/CBMiXkFVX3lxTE1GX1NLelZJcGVrbmstSlFoR0FaUElMdEhCQ3REbUxnWlIweGx4QmRLYUxRNm1SaDlFbkhaOEZhZzcyXzVxYVYyMlN2Y0FoejBYSXd2WFNZWXVIR1A2LWc?oc=5

## ğŸ”¥ è®¡ç®—æœºç§‘å­¦ / è½¯ä»¶å·¥ç¨‹

- **Achieving Productivity Gains with AI-based IDE features: A Journey at Google**  
  æ¥æºï¼šarXiv cs.SE (arXivï¼ˆè®ºæ–‡æ‘˜è¦ï¼‰)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šarXiv:2601.19964v1 Announce Type: new  Abstract: We discuss Google's journey in developing and refining two internal AI-based IDE features: code completion and natural-language-driven code transformation (Transform Code). We address challenges in latency, user experience and suggestion quality, all backed by rigorous experimentation. The article serves as an example of how to refine AI developer tools across the user interface, backend, and model layers, to deliver tangible productivity improvem...
  é“¾æ¥ï¼šhttps://arxiv.org/abs/2601.19964

- **Benchmarking Reward Hack Detection in Code Environments via Contrastive Analysis**  
  æ¥æºï¼šarXiv cs.SE (arXivï¼ˆè®ºæ–‡æ‘˜è¦ï¼‰)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šarXiv:2601.20103v1 Announce Type: new  Abstract: Recent advances in reinforcement learning for code generation have made robust environments essential to prevent reward hacking. As LLMs increasingly serve as evaluators in code-based RL, their ability to detect reward hacking remains understudied. In this paper, we propose a novel taxonomy of reward exploits spanning across 54 categories and introduce TRACE (Testing Reward Anomalies in Code Environments), a synthetically curated and human-verifie...
  é“¾æ¥ï¼šhttps://arxiv.org/abs/2601.20103

- **A Data-Informed Local Subspaces Method for Error-Bounded Lossy Compression of Large-Scale Scientific Datasets**  
  æ¥æºï¼šarXiv cs.DC (arXivï¼ˆè®ºæ–‡æ‘˜è¦ï¼‰)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šarXiv:2601.20113v1 Announce Type: new  Abstract: The growing volume of scientific simulation data presents a significant challenge for storage and transfer. Error-bounded lossy compression has emerged as a critical solution for mitigating these challenges, providing a means to reduce data size while ensuring that reconstructed data remains valid for scientific analysis. In this paper, we present a data-driven scientific data compressor, called Discontinuous Data-informed Local Subspaces (Discont...
  é“¾æ¥ï¼šhttps://arxiv.org/abs/2601.20113

- **StreamFusion: Scalable Sequence Parallelism for Distributed Inference of Diffusion Transformers on GPUs**  
  æ¥æºï¼šarXiv cs.DC (arXivï¼ˆè®ºæ–‡æ‘˜è¦ï¼‰)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šarXiv:2601.20273v1 Announce Type: new  Abstract: Diffusion Transformers (DiTs) have gained increasing adoption in high-quality image and video generation. As demand for higher-resolution images and longer videos increases, single-GPU inference becomes inefficient due to increased latency and large activation sizes. Current frameworks employ sequence parallelism (SP) techniques such as Ulysses Attention and Ring Attention to scale inference. However, these implementations have three primary limit...
  é“¾æ¥ï¼šhttps://arxiv.org/abs/2601.20273

- **From pixels to characters: The engineering behind GitHub Copilot CLIâ€™s animated ASCII banner**  
  æ¥æºï¼šGitHub Blog (åšå®¢)  
  æ‘˜è¦ï¼ˆå…¨æ–‡ï¼‰ï¼šAaron Winston @aaronwinston Aaron helps lead content strategy at GitHub with a focus on everything developers need to know to stay ahead of what's next. Also, he still likes the em dash despite its newfound bad rap.
  é“¾æ¥ï¼šhttps://github.blog/engineering/from-pixels-to-characters-the-engineering-behind-github-copilot-clis-animated-ascii-banner/

## ğŸ”¥ å·¥ç¨‹ / ç³»ç»Ÿ / å·¥å…·

- **From pixels to characters: The engineering behind GitHub Copilot CLIâ€™s animated ASCII banner**  
  æ¥æºï¼šGitHub Blog (åšå®¢)  
  æ‘˜è¦ï¼ˆå…¨æ–‡ï¼‰ï¼šAaron Winston @aaronwinston Aaron helps lead content strategy at GitHub with a focus on everything developers need to know to stay ahead of what's next. Also, he still likes the em dash despite its newfound bad rap.
  é“¾æ¥ï¼šhttps://github.blog/engineering/from-pixels-to-characters-the-engineering-behind-github-copilot-clis-animated-ascii-banner/

- **Year recap and future goals for the GitHub Innovation Graph**  
  æ¥æºï¼šGitHub Blog (åšå®¢)  
  æ‘˜è¦ï¼ˆå…¨æ–‡ï¼‰ï¼šHome / News & insights / Policy Year recap and future goals for the GitHub Innovation Graph Discover the latest trends and insights on public software development activity on GitHub with data from the Innovation Graph through Q3 2025. Kevin XuÂ·@khxu January 28, 2026 | 4 minutes Share: Todayâ€™s data release marks our second full year of regular releases since the launch of the GitHub Innovation Graph. The Innovation Graph serves as a stable, regularly updated source for aggregated statistics on pu...
  é“¾æ¥ï¼šhttps://github.blog/news-insights/policy-news-and-insights/year-recap-and-future-goals-for-the-github-innovation-graph/

- **7 learnings from Anders Hejlsberg: The architect behind C# and TypeScript**  
  æ¥æºï¼šGitHub Blog (åšå®¢)  
  æ‘˜è¦ï¼ˆå…¨æ–‡ï¼‰ï¼šAaron Winston @aaronwinston Aaron helps lead content strategy at GitHub with a focus on everything developers need to know to stay ahead of what's next. Also, he still likes the em dash despite its newfound bad rap.
  é“¾æ¥ï¼šhttps://github.blog/developer-skills/programming-languages-and-frameworks/7-learnings-from-anders-hejlsberg-the-architect-behind-c-and-typescript/

- **Help shape the future of open source in Europe**  
  æ¥æºï¼šGitHub Blog (åšå®¢)  
  æ‘˜è¦ï¼ˆå…¨æ–‡ï¼‰ï¼šMathias Schindler @mathiasschindler Mathias Schindler is passionate about open source, open content and open collaboration. For over 15 years, he has been involved in EU legislation on copyright, transparency and open data, both as an employee at German NGOs and also as a staffer for several members of various parliaments in Europe. He likes and writes encyclopedias.
  é“¾æ¥ï¼šhttps://github.blog/news-insights/policy-news-and-insights/help-shape-the-future-of-open-source-in-europe/

- **The Only Moat Left Is Knowing Things**  
  æ¥æºï¼šHacker News (æ–°é—»)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šArticle URL: https://growtika.com/blog/authenticity-edge Comments URL: https://news.ycombinator.com/item?id=46806959 Points: 9 # Comments: 2
  é“¾æ¥ï¼šhttps://growtika.com/blog/authenticity-edge

---
_è‡ªåŠ¨ç”Ÿæˆ Â· GitHub Actions_
