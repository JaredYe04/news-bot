# ğŸ§  ç§‘ç ” & æŠ€æœ¯çƒ­ç‚¹æ—¥æŠ¥

æ—¥æœŸï¼š2026-01-30 ä¸Šåˆ
ç”Ÿæˆæ—¶é—´ï¼š2026/01/30 08:23

## ğŸ“ ä»Šæ—¥æ€»ç»“

# 2026å¹´1æœˆ30æ—¥ ç§‘ç ”ä¸æŠ€æœ¯çƒ­ç‚¹æ–°é—»æ€»ç»“

## 1. ä»Šæ—¥æœ€é‡è¦çš„æŠ€æœ¯è¶‹åŠ¿å’Œçƒ­ç‚¹

### 1.1 NeuroAIï¼šç¥ç»ç§‘å­¦ä¸AIçš„æ·±åº¦èåˆ
ä»Šæ—¥å¤šç¯‡è®ºæ–‡ï¼ˆå¦‚arXiv:2601.19955ï¼‰èšç„¦äº**NeuroAI**è¿™ä¸€æ–°å…´äº¤å‰é¢†åŸŸã€‚æ ¸å¿ƒè§‚ç‚¹æ˜¯ï¼šå½“å‰ç¥ç»ç§‘å­¦ä¸äººå·¥æ™ºèƒ½è™½å„è‡ªå–å¾—çªç ´ï¼Œä½†è¿æ¥æ¾æ•£ã€‚æœªæ¥çš„å…³é”®æ–¹å‘åŒ…æ‹¬ï¼š
- **å…·èº«æ™ºèƒ½ï¼ˆEmbodimentï¼‰**ï¼šè®©AIç³»ç»Ÿæ‹¥æœ‰ç±»ä¼¼ç”Ÿç‰©ä½“çš„æ„ŸçŸ¥-è¡ŒåŠ¨å¾ªç¯
- **ç¥ç»å½¢æ€å·¥ç¨‹**ï¼šå¼€å‘å—å¤§è„‘å¯å‘çš„ç¡¬ä»¶æ¶æ„
- **äººç±»ä¸æœºå™¨å­¦ä¹ çš„ååŒ**ï¼šä»äººè„‘å­¦ä¹ æœºåˆ¶ä¸­æç‚¼æ–°ç®—æ³•

è¿™æ ‡å¿—ç€AIç ”ç©¶æ­£ä»çº¯ç²¹çš„å·¥ç¨‹æ–¹æ³•è½¬å‘**ç”Ÿç‰©å­¦å¯å‘**çš„èŒƒå¼ï¼Œå¯èƒ½è§£å†³å½“å‰AIåœ¨èƒ½æ•ˆã€æ³›åŒ–èƒ½åŠ›å’Œé€‚åº”æ€§æ–¹é¢çš„ç“¶é¢ˆã€‚

### 1.2 æ™ºèƒ½ä½“ï¼ˆAgentï¼‰æŠ€æœ¯çš„åŠ¡å®åŒ–ä¸è´¨ç–‘å¹¶å­˜
æ™ºèƒ½ä½“é¢†åŸŸå‘ˆç°çŸ›ç›¾æ€åŠ¿ï¼š
- **æŠ€æœ¯è¿›å±•**ï¼šSQ-BCPæ–¹æ³•ï¼ˆarXiv:2601.20014ï¼‰é€šè¿‡**èŒƒç•´è®ºè§„åˆ’**å’Œè‡ªæŸ¥è¯¢æœºåˆ¶ï¼Œè®©LLMåœ¨éƒ¨åˆ†å¯è§‚æµ‹ç¯å¢ƒä¸‹èƒ½ä¸»åŠ¨è¯¢é—®ç¼ºå¤±ä¿¡æ¯ï¼Œæ˜¾è‘—æå‡è§„åˆ’å¯é æ€§ã€‚
- **ç°å®åº”ç”¨**ï¼šå“ˆä½›å•†ä¸šè¯„è®ºè®¨è®ºä¼ä¸šå¦‚ä½•ä¸ºâ€œæ™ºèƒ½ä½“åŒ–AIâ€åšå‡†å¤‡ï¼ŒGitHubç­‰å¹³å°åˆ†äº«ç¼–ç æ™ºèƒ½ä½“çš„å®è·µç»éªŒã€‚
- **æ ¹æœ¬æ€§è´¨ç–‘**ï¼šFuturismæŠ¥é“æœ‰è®ºæ–‡æŒ‡å‡ºâ€œAIæ™ºèƒ½ä½“åœ¨æ•°å­¦ä¸Šæ— æ³•å®ŒæˆåŠŸèƒ½æ€§å·¥ä½œâ€ï¼Œè¿™å¼•å‘äº†å…³äºå½“å‰åŸºäºLLMçš„æ™ºèƒ½ä½“**èƒ½åŠ›è¾¹ç•Œ**çš„é‡è¦è®¨è®ºã€‚

### 1.3 RAGç³»ç»Ÿçš„æ¼”è¿›ï¼šä»æ£€ç´¢åˆ°ç†è§£
æ£€ç´¢å¢å¼ºç”Ÿæˆæ­£ç»å†ä¸¤é˜¶æ®µè¿›åŒ–ï¼š
- **æ¶æ„ä¼˜åŒ–**ï¼šLLaTTEï¼ˆarXiv:2601.20083ï¼‰åœ¨å¹¿å‘Šæ¨èä¸­éªŒè¯äº†æ¨èç³»ç»Ÿä¹Ÿå­˜åœ¨ç±»ä¼¼LLMçš„**å¹‚å¾‹ç¼©æ”¾è§„å¾‹**ï¼Œå¹¶é‡‡ç”¨å¼‚æ­¥ä¸¤é˜¶æ®µæ¶æ„å¹³è¡¡æ•ˆæœä¸å»¶è¿Ÿã€‚
- **å¯è§£é‡Šæ€§çªç ´**ï¼šIMRNNsï¼ˆarXiv:2601.20084ï¼‰é€šè¿‡åŠ¨æ€åµŒå…¥è°ƒåˆ¶ï¼Œé¦–æ¬¡è®©ç¨ å¯†æ£€ç´¢å™¨å…·å¤‡**åŒå‘å¯è§£é‡Šæ€§**ï¼Œèƒ½æ¸…æ™°å±•ç¤ºæŸ¥è¯¢ä¸æ–‡æ¡£çš„è¯­ä¹‰å¯¹é½è¿‡ç¨‹ã€‚
- **è¿­ä»£å¼RAGä¼˜åŠ¿æ˜¾ç°**ï¼šå¤šä¸ªæ¥æºè¯å®è¿­ä»£å¼RAGåœ¨11ç§LLMä¸Šè¡¨ç°ä¼˜äºâ€œé»„é‡‘ä¸Šä¸‹æ–‡â€ï¼Œè¯´æ˜åŠ¨æ€è°ƒæ•´æ£€ç´¢ç­–ç•¥æ¯”ä¸€æ¬¡æ€§æ£€ç´¢æ›´æœ‰æ•ˆã€‚

### 1.4 LLMæ£€æµ‹ä¸å¯¹é½çš„æ–°ç»´åº¦
- **ç”Ÿæˆæ–‡æœ¬æ£€æµ‹ä¸“ä¸šåŒ–**ï¼šLREADç ”ç©¶ï¼ˆarXiv:2601.19913ï¼‰æ˜¾ç¤ºï¼Œé€šè¿‡åŸºäºè¯„åˆ†æ ‡å‡†çš„è®¤çŸ¥æ ¡å‡†ï¼Œäººç±»æ£€æµ‹éŸ©è¯­LLMç”Ÿæˆæ–‡æœ¬çš„å‡†ç¡®ç‡å¯ä»ç›´è§‰é˜¶æ®µçš„65%æå‡è‡³ä¸“ä¸šé˜¶æ®µçš„89%ï¼Œè¯´æ˜æ£€æµ‹æ˜¯**å¯è®­ç»ƒæŠ€èƒ½**ã€‚
- **å¿ è¯šåº¦ç ”ç©¶å…´èµ·**ï¼šè¾¾ç‰¹èŒ…æ–¯å­¦é™¢ç ”ç©¶å¼€å§‹æ¢è®¨â€œè¯­è¨€æ¨¡å‹çš„å¿ è¯šåº¦â€â€”â€”å³æ¨¡å‹åœ¨ä¸åŒæ–‡åŒ–ã€æ”¿æ²»èƒŒæ™¯ä¸‹çš„è¾“å‡ºå€¾å‘æ€§ã€‚
- **å·¥å…·è°ƒç”¨ç¯å¢ƒé€‚é…**ï¼šæ–°ç ”ç©¶å…³æ³¨å¦‚ä½•åœ¨æ— çŠ¶æ€æ‰§è¡Œç¯å¢ƒä¸­æ¨¡æ‹Ÿå¤æ‚çš„å¤šè½®å·¥å…·è°ƒç”¨äº¤äº’ï¼Œè¿™å¯¹ä¼ä¸šçº§éƒ¨ç½²è‡³å…³é‡è¦ã€‚

### 1.5 å¼€å‘å·¥å…·é“¾çš„AIåŒ–æ·±å…¥
Googleåˆ†äº«å…¶AI IDEåŠŸèƒ½æ¼”è¿›ç»éªŒï¼ˆarXiv:2601.19964ï¼‰ï¼Œé‡ç‚¹è§£å†³ï¼š
- **å»¶è¿Ÿä¼˜åŒ–**ï¼šå°†ä»£ç è¡¥å…¨å»¶è¿Ÿæ§åˆ¶åœ¨100mså†…
- **ç”¨æˆ·ä½“éªŒè®¾è®¡**ï¼šå¦‚ä½•è®©AIå»ºè®®æ—¢æœ‰ç”¨åˆä¸å¹²æ‰°
- **è´¨é‡è¯„ä¼°ä½“ç³»**ï¼šå»ºç«‹ä¸¥è°¨çš„å®éªŒæ¡†æ¶è¡¡é‡ç”Ÿäº§åŠ›æå‡

åŒæ—¶ï¼ŒGitHubè¯¦ç»†æ‹†è§£äº†Copilot CLIä¸­ASCIIåŠ¨ç”»æ¨ªå¹…çš„å·¥ç¨‹å®ç°ï¼Œå±•ç¤ºäº†å°†åƒç´ è‰ºæœ¯å®æ—¶è½¬æ¢ä¸ºå­—ç¬¦ç”»çš„æŠ€æœ¯ç»†èŠ‚ã€‚

## 2. å€¼å¾—å…³æ³¨çš„ç ”ç©¶æ–¹å‘æˆ–çªç ´

### 2.1 èŒƒç•´è®ºå½¢å¼åŒ–æ–¹æ³•è¿›å…¥è§„åˆ’é¢†åŸŸ
SQ-BCPå°†èŒƒç•´è®ºçš„æ‹‰å›ï¼ˆpullbackï¼‰æ¦‚å¿µç”¨ä½œç›®æ ‡å…¼å®¹æ€§çš„å½¢å¼åŒ–è¯æ˜ï¼Œè¿™æ˜¯**å½¢å¼åŒ–æ–¹æ³•é¦–æ¬¡æ·±åº¦èå…¥LLMæ¨ç†è¿‡ç¨‹**ã€‚å¯èƒ½å¼€å¯ä¸€ä¸ªæ–°æ—¶ä»£ï¼šç”¨æ•°å­¦ç»“æ„ä¿è¯AIç³»ç»Ÿè¡Œä¸ºçš„å¯éªŒè¯æ€§ã€‚

### 2.2 æ•°æ®éšç§æ£€æµ‹çš„æ–°ç†è®ºåŸºç¡€
Gap-K%ï¼ˆarXiv:2601.19936ï¼‰ä»LLMé¢„è®­ç»ƒçš„ä¼˜åŒ–åŠ¨åŠ›å­¦è§’åº¦æå‡ºæ–°æ£€æµ‹æ–¹æ³•ã€‚æ ¸å¿ƒæ´å¯Ÿæ˜¯ï¼šè®­ç»ƒæ—¶æ¨¡å‹ä¼šæƒ©ç½štop-1é¢„æµ‹ä¸ç›®æ ‡tokençš„å·®å¼‚ï¼Œå› æ­¤åœ¨é¢„è®­ç»ƒæ•°æ®ä¸Šè¿™ç§â€œå·®è·â€ä¼šæ˜¾è‘—æ›´å°ã€‚è¿™ä¸ºç‰ˆæƒå’Œéšç§ä¿æŠ¤æä¾›äº†æ›´åšå®çš„ç†è®ºåŸºç¡€ã€‚

### 2.3 å»ä¸­å¿ƒåŒ–è”é‚¦å­¦ä¹ çš„äºŒé˜¶ä¼˜åŒ–
DecHWï¼ˆarXiv:2601.19938ï¼‰é€šè¿‡åˆ©ç”¨äºŒé˜¶ä¿¡æ¯å¤„ç†è®¾å¤‡é—´çš„å¼‚è´¨æ€§ï¼Œåœ¨ä¿æŒå»ä¸­å¿ƒåŒ–çš„åŒæ—¶æå‡æ”¶æ•›é€Ÿåº¦ã€‚è¿™å¯¹è¾¹ç¼˜è®¡ç®—å’Œç‰©è”ç½‘ä¸­çš„è”åˆå­¦ä¹ æœ‰é‡è¦æ„ä¹‰ã€‚

### 2.4 ç§‘å­¦æ•°æ®å‹ç¼©çš„æ•°æ®é©±åŠ¨æ–¹æ³•
Discontinuous DLSå‹ç¼©å™¨åˆ©ç”¨æ•°æ®æœ¬èº«çš„ç»“æ„ä¿¡æ¯æ„å»ºå±€éƒ¨å­ç©ºé—´ï¼Œåœ¨ä¿è¯è¯¯å·®è¾¹ç•Œçš„å‰æä¸‹æ˜¾è‘—æå‡å‹ç¼©ç‡ã€‚è¿™å¯¹æ°”å€™æ¨¡æ‹Ÿã€å¤©ä½“ç‰©ç†ç­‰äº§ç”ŸPBçº§æ•°æ®çš„é¢†åŸŸæ˜¯å…³é”®æŠ€æœ¯çªç ´ã€‚

## 3. ç®€è¦åˆ†æä¸å±•æœ›

ä»Šæ—¥æ–°é—»å‘ˆç°ä¸‰ä¸ªå®è§‚è¶‹åŠ¿ï¼š

ç¬¬ä¸€ï¼Œ**AIç ”ç©¶æ­£åœ¨â€œå¾€å›çœ‹â€å¯»æ‰¾çµæ„Ÿ**â€”â€”æ— è®ºæ˜¯å‘ç¥ç»ç§‘å­¦å¯»æ±‚æ¶æ„å¯å‘ï¼ˆNeuroAIï¼‰ï¼Œè¿˜æ˜¯å‘æ•°å­¦åŸºç¡€å¯»æ±‚å½¢å¼åŒ–ä¿è¯ï¼ˆèŒƒç•´è®ºè§„åˆ’ï¼‰ï¼Œéƒ½è¡¨æ˜å•çº¯æ‰©å¤§æ¨¡å‹è§„æ¨¡çš„é“è·¯é‡åˆ°ç“¶é¢ˆï¼Œéœ€è¦æ›´æ·±å±‚çš„åˆ›æ–°ã€‚

ç¬¬äºŒï¼Œ**å·¥ç¨‹å®è·µå¼€å§‹åå“ºç†è®ºç ”ç©¶**ã€‚Googleã€GitHubç­‰å·¥ä¸šç•Œçš„ç»éªŒåˆ†äº«æ˜¾ç¤ºï¼Œå¤§è§„æ¨¡éƒ¨ç½²æš´éœ²çš„çœŸå®é—®é¢˜ï¼ˆå¦‚å»¶è¿Ÿã€ç”¨æˆ·ä½“éªŒã€çŠ¶æ€ç®¡ç†ï¼‰æ­£åœ¨é©±åŠ¨å­¦æœ¯ç ”ç©¶çš„æ–°æ–¹å‘ã€‚

ç¬¬ä¸‰ï¼Œ**è¯„ä¼°ä½“ç³»æ—¥ç›Šç²¾ç»†åŒ–**ã€‚ä»æ£€æµ‹LLMç”Ÿæˆæ–‡æœ¬çš„æ ‡å‡†åŒ–è¯„åˆ†æ ‡å‡†ï¼Œåˆ°è¡¡é‡ç¼–ç æ™ºèƒ½ä½“æ˜¯å¦â€œçœŸæ­£å·¥ä½œâ€çš„æ•°å­¦æ¡†æ¶ï¼Œå†åˆ°è”é‚¦å­¦ä¹ ä¸­å¤„ç†å¼‚è´¨æ€§çš„é‡åŒ–æ–¹æ³•ï¼Œæ•´ä¸ªé¢†åŸŸæ­£åœ¨ä»â€œæ•ˆæœä¸é”™â€èµ°å‘â€œä¸¥æ ¼è¯æ˜â€ã€‚

å±•æœ›æœªæ¥6-12ä¸ªæœˆï¼š
- NeuroAIå¯èƒ½å‚¬ç”Ÿæ–°ä¸€ä»£èŠ‚èƒ½AIèŠ¯ç‰‡å’Œç®—æ³•
- RAGç³»ç»Ÿå°†æ™®éå…·å¤‡å¯è§£é‡Šæ€§å’Œè¿­ä»£èƒ½åŠ›
- AIå¼€å‘å·¥å…·å°†ä»â€œè¾…åŠ©ç¼–ç â€å‡çº§ä¸ºâ€œè¾…åŠ©è½¯ä»¶è®¾è®¡â€
- LLMæ£€æµ‹å°†æˆä¸ºæ ‡å‡†åŒ–æŠ€èƒ½è¿›å…¥æ•™è‚²ä½“ç³»

## 4. å¯¹ä¸åŒè§’è‰²çš„å»ºè®®

### ğŸ”§ **å¼€å‘è€…**
- **ç«‹å³è¡ŒåŠ¨é¡¹**ï¼š
  1. å®éªŒè¿­ä»£å¼RAGæ¶æ„ï¼Œå¯¹æ¯”ä¸ä¼ ç»ŸRAGçš„æ•ˆæœå·®å¼‚
  2. åœ¨å·¥å…·è°ƒç”¨å®ç°ä¸­è€ƒè™‘æ— çŠ¶æ€ç¯å¢ƒé€‚é…æ€§
  3. å…³æ³¨GitHub Copilotç­‰å·¥å…·çš„APIæ›´æ–°ï¼Œç‰¹åˆ«æ˜¯æ–°çš„ä»£ç è½¬æ¢åŠŸèƒ½

- **å­¦ä¹ æ–¹å‘**ï¼š
  äº†è§£èŒƒç•´è®ºåŸºæœ¬æ¦‚å¿µï¼ˆè‡³å°‘ç†è§£æ‹‰å›ã€æ¨å‡ºç­‰æ„é€ ï¼‰ï¼Œè¿™å¯èƒ½æ˜¯ä¸‹ä¸€ä»£AIç³»ç»Ÿçš„å½¢å¼åŒ–åŸºç¡€ã€‚åŒæ—¶å…³æ³¨NeuroAIè¿›å±•ï¼Œæ€è€ƒå¦‚ä½•å°†ç”Ÿç‰©å¯å‘æœºåˆ¶åº”ç”¨äºå®é™…ç³»ç»Ÿè®¾è®¡ã€‚

### ğŸ§ª **ç ”ç©¶äººå‘˜**
- **å‰æ²¿è¯¾é¢˜å»ºè®®**ï¼š
  1. NeuroAIçš„å…·ä½“å®ç°è·¯å¾„â€”â€”å¦‚ä½•å°†ç¥ç»ç§‘å­¦å‘ç°è½¬åŒ–ä¸ºå¯è®­ç»ƒçš„ç®—æ³•æ¨¡å—ï¼Ÿ
  2. LLMå¿ è¯šåº¦çš„é‡åŒ–æµ‹é‡æ¡†æ¶åŠå…¶ç¤¾ä¼šå½±å“
  3. AIæ™ºèƒ½ä½“â€œåŠŸèƒ½æ€§å·¥ä½œâ€çš„ä¸¥æ ¼å®šä¹‰ä¸è¯„ä¼°åŸºå‡†

- **åˆä½œæœºä¼š**ï¼š
  ä¸»åŠ¨ä¸ç¥ç»ç§‘å­¦å®¶ã€æ•°å­¦å®¶ã€è®¤çŸ¥ç§‘å­¦å®¶å»ºç«‹è·¨å­¦ç§‘åˆä½œã€‚ä»Šæ—¥å¤šç¯‡é«˜å½±å“åŠ›è®ºæ–‡éƒ½æ¥è‡ªäº¤å‰å›¢é˜Ÿã€‚

### ğŸ“ **å­¦ç”Ÿ**
- **è¯¾ç¨‹è¡¥å……å»ºè®®**ï¼š
  è®¡ç®—æœºç§‘å­¦ä¸“ä¸šå­¦ç”Ÿåº”é€‰ä¿®è®¤çŸ¥ç§‘å­¦ã€ç¥ç»ç§‘å­¦å¯¼è®ºè¯¾ç¨‹ï¼›åä¹‹äº¦ç„¶ã€‚æœªæ¥çš„çªç ´æœ€å¯èƒ½å‘ç”Ÿåœ¨äº¤å‰åœ°å¸¦ã€‚

- **å®è·µé¡¹ç›®æ€è·¯**ï¼š
  1. å¤ç°Gap-K%æ–¹æ³•å¹¶æ‰©å±•åˆ°å¤šè¯­è¨€åœºæ™¯
  2. æ„å»ºå°å‹èŒƒç•´è®ºè§„åˆ’æ¼”ç¤ºç³»ç»Ÿ
  3. å¼€å‘é’ˆå¯¹ç‰¹å®šé¢†åŸŸï¼ˆå¦‚æ³•å¾‹ã€åŒ»ç–—ï¼‰çš„LLMç”Ÿæˆæ–‡æœ¬æ£€æµ‹å·¥å…·

### ğŸ“Š **æŠ€æœ¯ç®¡ç†è€…**
- **æˆ˜ç•¥å‡†å¤‡**ï¼š
  1. è¯„ä¼°å›¢é˜Ÿå¯¹â€œæ™ºèƒ½ä½“åŒ–AIâ€çš„å‡†å¤‡ç¨‹åº¦â€”â€”ä¸ä»…æ˜¯æŠ€æœ¯èƒ½åŠ›ï¼Œè¿˜åŒ…æ‹¬å·¥ä½œæµç¨‹è°ƒæ•´
  2. å»ºç«‹AIå·¥å…·çš„ç”Ÿäº§åŠ›å½±å“è¯„ä¼°ä½“ç³»ï¼ˆå‚è€ƒGoogleçš„ç»éªŒï¼‰
  3. å…³æ³¨å»ä¸­å¿ƒåŒ–è”é‚¦å­¦ä¹ åœ¨æ•°æ®éšç§æ³•è§„è¶‹ä¸¥èƒŒæ™¯ä¸‹çš„åº”ç”¨æ½œåŠ›

ä»Šæ—¥çš„æŠ€æœ¯å›¾æ™¯æ˜¾ç¤ºäº†ä¸€ä¸ªå…³é”®è½¬æŠ˜ç‚¹ï¼šAIæ­£åœ¨ä»â€œæš´åŠ›è®¡ç®—â€æ—¶ä»£èµ°å‘â€œç²¾å·§è®¾è®¡â€æ—¶ä»£ã€‚é‚£äº›èƒ½å¤Ÿèåˆå¤šä¸ªå­¦ç§‘è§†è§’ã€æ—¢æ‡‚ç®—æ³•åˆæ‡‚ç¡¬ä»¶ã€æ—¢ä¼šç¼–ç åˆç†è§£äººç±»è®¤çŸ¥çš„å¤åˆå‹äººæ‰å°†åœ¨è¿™ä¸€è½®è½¬å‹ä¸­è·å¾—æœ€å¤§ä¼˜åŠ¿ã€‚

---
*æ€»ç»“åŸºäº2026å¹´1æœˆ30æ—¥08:23æ”¶é›†çš„çƒ­ç‚¹æ–°é—»ã€‚æŠ€æœ¯å‘å±•æ—¥æ–°æœˆå¼‚ï¼Œå»ºè®®è¯»è€…æŒç»­è·Ÿè¸ªåŸå§‹è®ºæ–‡å’Œå®˜æ–¹å‘å¸ƒä»¥è·å–æœ€æ–°è¿›å±•ã€‚*

---

## ğŸ”¥ AI / LLM

- **NeuroAI and Beyond**  
  æ¥æºï¼šarXiv cs.AI (arXivï¼ˆè®ºæ–‡æ‘˜è¦ï¼‰)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šarXiv:2601.19955v1 Announce Type: new  Abstract: Neuroscience and Artificial Intelligence (AI) have made significant progress in the past few years but have only been loosely inter-connected. Based on a workshop held in August 2025, we identify current and future areas of synergism between these two fields. We focus on the subareas of embodiment, language and communication, robotics, learning in humans and machines and Neuromorphic engineering to take stock of the progress made so far, and possi...
  é“¾æ¥ï¼šhttps://arxiv.org/abs/2601.19955

- **Teaching LLMs to Ask: Self-Querying Category-Theoretic Planning for Under-Specified Reasoning**  
  æ¥æºï¼šarXiv cs.AI (arXivï¼ˆè®ºæ–‡æ‘˜è¦ï¼‰)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šarXiv:2601.20014v1 Announce Type: new  Abstract: Inference-time planning with large language models frequently breaks under partial observability: when task-critical preconditions are not specified at query time, models tend to hallucinate missing facts or produce plans that violate hard constraints. We introduce \textbf{Self-Querying Bidirectional Categorical Planning (SQ-BCP)}, which explicitly represents precondition status (\texttt{Sat}/\texttt{Viol}/\texttt{Unk}) and resolves unknowns via (...
  é“¾æ¥ï¼šhttps://arxiv.org/abs/2601.20014

- **Gap-K%: Measuring Top-1 Prediction Gap for Detecting Pretraining Data**  
  æ¥æºï¼šarXiv cs.LG (arXivï¼ˆè®ºæ–‡æ‘˜è¦ï¼‰)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šarXiv:2601.19936v1 Announce Type: new  Abstract: The opacity of massive pretraining corpora in Large Language Models (LLMs) raises significant privacy and copyright concerns, making pretraining data detection a critical challenge. Existing state-of-the-art methods typically rely on token likelihoods, yet they often overlook the divergence from the model's top-1 prediction and local correlation between adjacent tokens. In this work, we propose Gap-K%, a novel pretraining data detection method gro...
  é“¾æ¥ï¼šhttps://arxiv.org/abs/2601.19936

- **DecHW: Heterogeneous Decentralized Federated Learning Exploiting Second-Order Information**  
  æ¥æºï¼šarXiv cs.LG (arXivï¼ˆè®ºæ–‡æ‘˜è¦ï¼‰)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šarXiv:2601.19938v1 Announce Type: new  Abstract: Decentralized Federated Learning (DFL) is a serverless collaborative machine learning paradigm where devices collaborate directly with neighbouring devices to exchange model information for learning a generalized model. However, variations in individual experiences and different levels of device interactions lead to data and model initialization heterogeneities across devices. Such heterogeneities leave variations in local model parameters across...
  é“¾æ¥ï¼šhttps://arxiv.org/abs/2601.19938

- **Inside OpenAIâ€™s in-house data agent**  
  æ¥æºï¼šOpenAI Blog (åšå®¢)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šHow OpenAI built an in-house AI data agent that uses GPT-5, Codex, and memory to reason over massive datasets and deliver reliable insights in minutes.
  é“¾æ¥ï¼šhttps://openai.com/index/inside-our-in-house-data-agent

## ğŸ”¥ Agent / æ™ºèƒ½ä½“

- **NeuroAI and Beyond**  
  æ¥æºï¼šarXiv cs.AI (arXivï¼ˆè®ºæ–‡æ‘˜è¦ï¼‰)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šarXiv:2601.19955v1 Announce Type: new  Abstract: Neuroscience and Artificial Intelligence (AI) have made significant progress in the past few years but have only been loosely inter-connected. Based on a workshop held in August 2025, we identify current and future areas of synergism between these two fields. We focus on the subareas of embodiment, language and communication, robotics, learning in humans and machines and Neuromorphic engineering to take stock of the progress made so far, and possi...
  é“¾æ¥ï¼šhttps://arxiv.org/abs/2601.19955

- **Teaching LLMs to Ask: Self-Querying Category-Theoretic Planning for Under-Specified Reasoning**  
  æ¥æºï¼šarXiv cs.AI (arXivï¼ˆè®ºæ–‡æ‘˜è¦ï¼‰)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šarXiv:2601.20014v1 Announce Type: new  Abstract: Inference-time planning with large language models frequently breaks under partial observability: when task-critical preconditions are not specified at query time, models tend to hallucinate missing facts or produce plans that violate hard constraints. We introduce \textbf{Self-Querying Bidirectional Categorical Planning (SQ-BCP)}, which explicitly represents precondition status (\texttt{Sat}/\texttt{Viol}/\texttt{Unk}) and resolves unknowns via (...
  é“¾æ¥ï¼šhttps://arxiv.org/abs/2601.20014

- **Preparing Your Brand for Agentic AI - Harvard Business Review**  
  æ¥æºï¼šGoogle News - AI Agents (æ–°é—»)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šPreparing Your Brand for Agentic AIÂ Â Harvard Business Review
  é“¾æ¥ï¼šhttps://news.google.com/rss/articles/CBMia0FVX3lxTE9naUNGRzY4UjJLOE4ySkYtQmpDdExIUnh0ZUFtTVJYbzBMZWFmVWt0U1RWNlp4TngtS0NYNzY2UlB1bjEyVHZSa1U0eTlsVnJwMG8wejhhLUw1VjFucmpVLXJfT1RYMWpOMTkw?oc=5

- **Coding Agents for Investigative Journalism | by Nick Hagar | Jan, 2026 - Generative AI in the Newsroom**  
  æ¥æºï¼šGoogle News - AI Agents (æ–°é—»)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šCoding Agents for Investigative Journalism | by Nick Hagar | Jan, 2026Â Â Generative AI in the Newsroom
  é“¾æ¥ï¼šhttps://news.google.com/rss/articles/CBMilAFBVV95cUxOdmdlNEZjWnREdXk5ZlB3d3hvbEhKdElJbDA3T3VBVWV5ajNPeFdfMWZaSy1IU0RfTWFRMjllNTR5U3lkaUloRGpma0k0NWdFcTNrM25qUDJMdUNWbTIyRnM3VjVsTGloTl9JSVA5VXR1QXo5YUNMcXJuX1l5ekc2YVdlMDFzX3J5bGlLMTRnNl9ZZ3c1?oc=5

- **AI Agents Are Mathematically Incapable of Doing Functional Work, Paper Finds - Futurism**  
  æ¥æºï¼šGoogle News - AI Agents (æ–°é—»)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šAI Agents Are Mathematically Incapable of Doing Functional Work, Paper FindsÂ Â Futurism
  é“¾æ¥ï¼šhttps://news.google.com/rss/articles/CBMieEFVX3lxTE5LOEhZX290QURPeEh5dFhKeUt0ck9LT3RmUzM4b1FvLXdWSWxCc0JnNmYzTlE4X2x1eGV2bUxEazZTcV8tV1lnNDhnODlkY29yMGdZdkxUX0wzMEV1U3BuZ1pFQXdWVm1LaER5RmQ3RlVKY1BJcWFfNQ?oc=5

## ğŸ”¥ RAG / æ£€ç´¢å¢å¼ºç”Ÿæˆ

- **NeuroAI and Beyond**  
  æ¥æºï¼šarXiv cs.AI (arXivï¼ˆè®ºæ–‡æ‘˜è¦ï¼‰)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šarXiv:2601.19955v1 Announce Type: new  Abstract: Neuroscience and Artificial Intelligence (AI) have made significant progress in the past few years but have only been loosely inter-connected. Based on a workshop held in August 2025, we identify current and future areas of synergism between these two fields. We focus on the subareas of embodiment, language and communication, robotics, learning in humans and machines and Neuromorphic engineering to take stock of the progress made so far, and possi...
  é“¾æ¥ï¼šhttps://arxiv.org/abs/2601.19955

- **Teaching LLMs to Ask: Self-Querying Category-Theoretic Planning for Under-Specified Reasoning**  
  æ¥æºï¼šarXiv cs.AI (arXivï¼ˆè®ºæ–‡æ‘˜è¦ï¼‰)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šarXiv:2601.20014v1 Announce Type: new  Abstract: Inference-time planning with large language models frequently breaks under partial observability: when task-critical preconditions are not specified at query time, models tend to hallucinate missing facts or produce plans that violate hard constraints. We introduce \textbf{Self-Querying Bidirectional Categorical Planning (SQ-BCP)}, which explicitly represents precondition status (\texttt{Sat}/\texttt{Viol}/\texttt{Unk}) and resolves unknowns via (...
  é“¾æ¥ï¼šhttps://arxiv.org/abs/2601.20014

- **LLaTTE: Scaling Laws for Multi-Stage Sequence Modeling in Large-Scale Ads Recommendation**  
  æ¥æºï¼šarXiv cs.IR (arXivï¼ˆè®ºæ–‡æ‘˜è¦ï¼‰)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šarXiv:2601.20083v1 Announce Type: new  Abstract: We present LLaTTE (LLM-Style Latent Transformers for Temporal Events), a scalable transformer architecture for production ads recommendation. Through systematic experiments, we demonstrate that sequence modeling in recommendation systems follows predictable power-law scaling similar to LLMs. Crucially, we find that semantic features bend the scaling curve: they are a prerequisite for scaling, enabling the model to effectively utilize the capacity...
  é“¾æ¥ï¼šhttps://arxiv.org/abs/2601.20083

- **IMRNNs: An Efficient Method for Interpretable Dense Retrieval via Embedding Modulation**  
  æ¥æºï¼šarXiv cs.IR (arXivï¼ˆè®ºæ–‡æ‘˜è¦ï¼‰)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šarXiv:2601.20084v1 Announce Type: new  Abstract: Interpretability in black-box dense retrievers remains a central challenge in Retrieval-Augmented Generation (RAG). Understanding how queries and documents semantically interact is critical for diagnosing retrieval behavior and improving model design. However, existing dense retrievers rely on static embeddings for both queries and documents, which obscures this bidirectional relationship. Post-hoc approaches such as re-rankers are computationally...
  é“¾æ¥ï¼šhttps://arxiv.org/abs/2601.20084

- **Iterative RAG Achieves Superior Performance To Gold Context In 11 LLMs - Quantum Zeitgeist**  
  æ¥æºï¼šGoogle News - RAG (æ–°é—»)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šIterative RAG Achieves Superior Performance To Gold Context In 11 LLMsÂ Â Quantum Zeitgeist
  é“¾æ¥ï¼šhttps://news.google.com/rss/articles/CBMihAFBVV95cUxORVJhTURrMm1iMGhOZ1BTYzVjYUhUMkxkbW1ETXNqcHRXYUNyWU4ycVVUR1R1dmVGdGhIZXZ6ekM4NE45ZV9yRGoyQ0N3bHR6ZHY0WDFwN2pEYmdhdzFZTjR3TDdHVGxfcVFPbl9PMXhIZjRNUmZ5M05jckM1aFI0UkszckU?oc=5

## ğŸ”¥ LLM / å¤§è¯­è¨€æ¨¡å‹

- **From Intuition to Expertise: Rubric-Based Cognitive Calibration for Human Detection of LLM-Generated Korean Text**  
  æ¥æºï¼šarXiv cs.CL (arXivï¼ˆè®ºæ–‡æ‘˜è¦ï¼‰)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šarXiv:2601.19913v1 Announce Type: new  Abstract: Distinguishing human-written Korean text from fluent LLM outputs remains difficult even for linguistically trained readers, who can over-trust surface well-formedness. We study whether expert detection can be treated as a learnable skill and improved through structured calibration. We introduce LREAD, a rubric derived from national Korean writing standards and adapted to target micro-level artifacts (e.g., punctuation optionality, spacing behavior...
  é“¾æ¥ï¼šhttps://arxiv.org/abs/2601.19913

- **Simulating Complex Multi-Turn Tool Calling Interactions in Stateless Execution Environments**  
  æ¥æºï¼šarXiv cs.CL (arXivï¼ˆè®ºæ–‡æ‘˜è¦ï¼‰)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šarXiv:2601.19914v1 Announce Type: new  Abstract: Synthetic data has proven itself to be a valuable resource for tuning smaller, cost-effective language models to handle the complexities of multi-turn tool calling conversations. While many frameworks and systems for producing synthetic multi-turn tool calling data have been proposed, prior works have frequently assumed that any tool calling interactions will take place in an execution environment that maintains state. When such an environment is...
  é“¾æ¥ï¼šhttps://arxiv.org/abs/2601.19914

- **Mapping surprise in the human mind, with help from AI - news.uchicago.edu**  
  æ¥æºï¼šGoogle News - LLM (æ–°é—»)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šMapping surprise in the human mind, with help from AIÂ Â news.uchicago.edu
  é“¾æ¥ï¼šhttps://news.google.com/rss/articles/CBMidkFVX3lxTE5qbkR3djVKVzh2WDl1QlRxWG9xWEtSenJYM2pDMVVmTGFYX3NLNjdLbXAxNzdPakNNMzdPSXAwWWtqUVJ2QmgyX3FBWmNnbkwyZE1udmViZ1E3VlFYT2dJeGRKRURwa2pONHlPVE9MemVYMlljWkE?oc=5

- **Making large language models reliable data science programming copilots for biomedical research - Nature**  
  æ¥æºï¼šGoogle News - LLM (æ–°é—»)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šMaking large language models reliable data science programming copilots for biomedical researchÂ Â Nature
  é“¾æ¥ï¼šhttps://news.google.com/rss/articles/CBMiX0FVX3lxTE50QktselJoYnR6SEdDSHQxUVBpVHIzZ3VWY3NQM1VCWUJPRjV6TTFMcC1YTXh1eGJlQlktZ1FFRGNhajRQX3dxc09iSEpTM2NHTDgwbHZZTndaQjlucm40?oc=5

- **Student Research Examines Loyalties of Language Models - Dartmouth**  
  æ¥æºï¼šGoogle News - LLM (æ–°é—»)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šStudent Research Examines Loyalties of Language ModelsÂ Â Dartmouth
  é“¾æ¥ï¼šhttps://news.google.com/rss/articles/CBMilgFBVV95cUxPLXVCTGZ1ODloaERLZW9DcDU3R3JMdmp5Q3BXODRsRXJPMzdqWjFsZE4zSld5Nld1VGpxLVFKLW1pNXNxb0dGR2ZtX2NBcHNXLWxBVEk3RnFXN0RCdEstUTdUcmpUV2Z1VFpYZVp6VFBkUGxRQU1WR1VibnRJbTdxaElxMmQweE14eUR3MHZzNlFtNzhZX1E?oc=5

## ğŸ”¥ è®¡ç®—æœºç§‘å­¦ / è½¯ä»¶å·¥ç¨‹

- **Achieving Productivity Gains with AI-based IDE features: A Journey at Google**  
  æ¥æºï¼šarXiv cs.SE (arXivï¼ˆè®ºæ–‡æ‘˜è¦ï¼‰)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šarXiv:2601.19964v1 Announce Type: new  Abstract: We discuss Google's journey in developing and refining two internal AI-based IDE features: code completion and natural-language-driven code transformation (Transform Code). We address challenges in latency, user experience and suggestion quality, all backed by rigorous experimentation. The article serves as an example of how to refine AI developer tools across the user interface, backend, and model layers, to deliver tangible productivity improvem...
  é“¾æ¥ï¼šhttps://arxiv.org/abs/2601.19964

- **Benchmarking Reward Hack Detection in Code Environments via Contrastive Analysis**  
  æ¥æºï¼šarXiv cs.SE (arXivï¼ˆè®ºæ–‡æ‘˜è¦ï¼‰)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šarXiv:2601.20103v1 Announce Type: new  Abstract: Recent advances in reinforcement learning for code generation have made robust environments essential to prevent reward hacking. As LLMs increasingly serve as evaluators in code-based RL, their ability to detect reward hacking remains understudied. In this paper, we propose a novel taxonomy of reward exploits spanning across 54 categories and introduce TRACE (Testing Reward Anomalies in Code Environments), a synthetically curated and human-verifie...
  é“¾æ¥ï¼šhttps://arxiv.org/abs/2601.20103

- **A Data-Informed Local Subspaces Method for Error-Bounded Lossy Compression of Large-Scale Scientific Datasets**  
  æ¥æºï¼šarXiv cs.DC (arXivï¼ˆè®ºæ–‡æ‘˜è¦ï¼‰)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šarXiv:2601.20113v1 Announce Type: new  Abstract: The growing volume of scientific simulation data presents a significant challenge for storage and transfer. Error-bounded lossy compression has emerged as a critical solution for mitigating these challenges, providing a means to reduce data size while ensuring that reconstructed data remains valid for scientific analysis. In this paper, we present a data-driven scientific data compressor, called Discontinuous Data-informed Local Subspaces (Discont...
  é“¾æ¥ï¼šhttps://arxiv.org/abs/2601.20113

- **StreamFusion: Scalable Sequence Parallelism for Distributed Inference of Diffusion Transformers on GPUs**  
  æ¥æºï¼šarXiv cs.DC (arXivï¼ˆè®ºæ–‡æ‘˜è¦ï¼‰)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šarXiv:2601.20273v1 Announce Type: new  Abstract: Diffusion Transformers (DiTs) have gained increasing adoption in high-quality image and video generation. As demand for higher-resolution images and longer videos increases, single-GPU inference becomes inefficient due to increased latency and large activation sizes. Current frameworks employ sequence parallelism (SP) techniques such as Ulysses Attention and Ring Attention to scale inference. However, these implementations have three primary limit...
  é“¾æ¥ï¼šhttps://arxiv.org/abs/2601.20273

- **From pixels to characters: The engineering behind GitHub Copilot CLIâ€™s animated ASCII banner**  
  æ¥æºï¼šGitHub Blog (åšå®¢)  
  æ‘˜è¦ï¼ˆå…¨æ–‡ï¼‰ï¼šAaron Winston @aaronwinston Aaron helps lead content strategy at GitHub with a focus on everything developers need to know to stay ahead of what's next. Also, he still likes the em dash despite its newfound bad rap.
  é“¾æ¥ï¼šhttps://github.blog/engineering/from-pixels-to-characters-the-engineering-behind-github-copilot-clis-animated-ascii-banner/

## ğŸ”¥ å·¥ç¨‹ / ç³»ç»Ÿ / å·¥å…·

- **From pixels to characters: The engineering behind GitHub Copilot CLIâ€™s animated ASCII banner**  
  æ¥æºï¼šGitHub Blog (åšå®¢)  
  æ‘˜è¦ï¼ˆå…¨æ–‡ï¼‰ï¼šAaron Winston @aaronwinston Aaron helps lead content strategy at GitHub with a focus on everything developers need to know to stay ahead of what's next. Also, he still likes the em dash despite its newfound bad rap.
  é“¾æ¥ï¼šhttps://github.blog/engineering/from-pixels-to-characters-the-engineering-behind-github-copilot-clis-animated-ascii-banner/

- **Year recap and future goals for the GitHub Innovation Graph**  
  æ¥æºï¼šGitHub Blog (åšå®¢)  
  æ‘˜è¦ï¼ˆå…¨æ–‡ï¼‰ï¼šHome / News & insights / Policy Year recap and future goals for the GitHub Innovation Graph Discover the latest trends and insights on public software development activity on GitHub with data from the Innovation Graph through Q3 2025. Kevin XuÂ·@khxu January 28, 2026 | 4 minutes Share: Todayâ€™s data release marks our second full year of regular releases since the launch of the GitHub Innovation Graph. The Innovation Graph serves as a stable, regularly updated source for aggregated statistics on pu...
  é“¾æ¥ï¼šhttps://github.blog/news-insights/policy-news-and-insights/year-recap-and-future-goals-for-the-github-innovation-graph/

- **7 learnings from Anders Hejlsberg: The architect behind C# and TypeScript**  
  æ¥æºï¼šGitHub Blog (åšå®¢)  
  æ‘˜è¦ï¼ˆå…¨æ–‡ï¼‰ï¼šAaron Winston @aaronwinston Aaron helps lead content strategy at GitHub with a focus on everything developers need to know to stay ahead of what's next. Also, he still likes the em dash despite its newfound bad rap.
  é“¾æ¥ï¼šhttps://github.blog/developer-skills/programming-languages-and-frameworks/7-learnings-from-anders-hejlsberg-the-architect-behind-c-and-typescript/

- **Help shape the future of open source in Europe**  
  æ¥æºï¼šGitHub Blog (åšå®¢)  
  æ‘˜è¦ï¼ˆå…¨æ–‡ï¼‰ï¼šMathias Schindler @mathiasschindler Mathias Schindler is passionate about open source, open content and open collaboration. For over 15 years, he has been involved in EU legislation on copyright, transparency and open data, both as an employee at German NGOs and also as a staffer for several members of various parliaments in Europe. He likes and writes encyclopedias.
  é“¾æ¥ï¼šhttps://github.blog/news-insights/policy-news-and-insights/help-shape-the-future-of-open-source-in-europe/

- **What the Success of Coding Agents Teaches Us about AI Systems in General**  
  æ¥æºï¼šHacker News (æ–°é—»)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šArticle URL: https://softwarefordays.com/post/software-is-mostly-all-you-need/ Comments URL: https://news.ycombinator.com/item?id=46818154 Points: 6 # Comments: 3
  é“¾æ¥ï¼šhttps://softwarefordays.com/post/software-is-mostly-all-you-need/

---
_è‡ªåŠ¨ç”Ÿæˆ Â· GitHub Actions_
